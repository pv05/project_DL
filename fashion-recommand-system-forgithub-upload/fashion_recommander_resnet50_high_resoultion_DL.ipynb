{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZaEUg9sAf2p"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD8yY36CA4-g",
        "outputId": "0eb663ef-b172-4ce8-8208-857e11b8efff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading fashion-product-images-dataset.zip to /content\n",
            "100% 23.1G/23.1G [07:43<00:00, 91.9MB/s]\n",
            "100% 23.1G/23.1G [07:43<00:00, 53.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7gMz8FwwCJUa",
        "outputId": "8ec66f73-598f-4de9-bb5e-44ac610f1ebc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjTq-hDoBsN4"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade tensorflow==2.3.1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbAnhoqvA8wF"
      },
      "outputs": [],
      "source": [
        "# now unzip the code\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(r'/content/fashion-product-images-dataset.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjbsSOe4BAfk"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA4d7fVIBAiE"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(weights = 'imagenet',include_top=False,input_shape=(224,224,3)) # we have to scalled down their shape coz, it is standdard size of the resnet50\n",
        "# include_top= False | why? coz, we put our top layer or inshort we replce the top layer\n",
        "model.trainable = False # we r not going to train model coz it alredy trained on imagent dataset so, we r just going to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOUuHwUZBAk3"
      },
      "outputs": [],
      "source": [
        "# here we use our top layer\n",
        "model = tensorflow.keras.Sequential([\n",
        "        model, # it is all ResNet50 model without top layer\n",
        "        GlobalAveragePooling2D() # here we added outr top layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vla_SOo7BAne",
        "outputId": "987341d2-4185-498f-9238-7264d98f672b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "=================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PVvlwTRBAqM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import os "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IOqdU7ZBAst"
      },
      "outputs": [],
      "source": [
        "def extract_features(img_path,model):\n",
        "    img = image.load_img(img_path,target_size=(224,224)) # load our image one by one with 224x224 resoulution\n",
        "    img_array = image.img_to_array(img) # it convert that upper image into array format\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0) # keras is going to read our image but in batchs so thats why we give iamge with batch numbers like (1,224,244,3) 1--> batch  | 224x224 --->resouliton | 3 is color com bination RGB\n",
        "    preprocessed_img = preprocess_input(expanded_img_array) # it convert RGB to BGR coz, this model is based on imagnet dataset, so that, we have to convert our images also in that form which imagnet dataset have, and imagnet dataset's image in BGR from (not RGB) that why we convert our images also into RGB to BGR format\n",
        "    result = model.predict(preprocessed_img).flatten() # we going to predict our model but in 1d array form that why we put flatten()  \n",
        "    normalized_result = result / norm(result) # this process is give values between 0 to 1 like(0,0.0025,0.125,0.112,0.1574585,1))\n",
        "    # norm() function is used to convert for normlize the values\n",
        "    return normalized_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR92MvLCGHxd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd74HEGiBAvT"
      },
      "outputs": [],
      "source": [
        "filenames = [] # this list have to store full path of our images with the help of below loop\n",
        "for file in os.listdir('/content/fashion-dataset/images'):\n",
        "  filenames.append(os.path.join('/content/fashion-dataset/images',file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MDSq60wHVKC"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm # for loop tracking in percentage form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z8jppqHBAxi",
        "outputId": "6edb7e1e-7386-45a4-ef45-e5715515877b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44441/44441 [3:12:50<00:00,  3.84it/s]\n"
          ]
        }
      ],
      "source": [
        "features_list = [] # this list have to store our images some values with is called feature extracted values , thats the value is classifed our images like( shirt image, bat image, jacket image etc)\n",
        "for file in tqdm(filenames):\n",
        "  features_list.append(extract_features(file,model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyiqX9HxBA0M"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(features_list ,open('embeddings1.pkl','wb'))\n",
        "pickle.dump(filenames ,open('filenames1.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_0ZsGYABA3I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeCf-c4OBA5c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1WpOYYxBA8I"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Euu6z1ABA-X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auiVykqWBBBD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNbJ9EADBBD7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYCulAvZBBHM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}